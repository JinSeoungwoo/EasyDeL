from ..utilities import FileBuffer
from runtime.llcl import num_cores
import math
from algorithm.functional import vectorize, parallelize, parallelize
from tensor import Tensor, TensorSpec, TensorShape
from ..tensor_utils import (
    TensorSlice,
    batch_matmul_row,
    rmsnorm,
    matmul_row,
    tensor_add,
    scope_softmax,
)
from memory import memset_zero


struct LlamaConfig:
    var hidden_size: Int
    var num_attention_heads: Int
    var num_hidden_layers: Int
    var vocab_size: Int
    var epsilon: Float32
    var number_rep_kv: Int
    var max_position_embeddings: Int
    var num_key_value_heads: Int
    var head_dims: Int
    var kv_dims: Int
    var intermediate_size: Int

    fn __init__(
        inout self: Self,
        hidden_size: Int,
        num_attention_heads: Int,
        num_hidden_layers: Int,
        vocab_size: Int,
        epsilon: Float32,
        number_rep_kv: Int,
        max_position_embeddings: Int,
        num_key_value_heads: Int,
        intermediate_size: Int,
    ) -> None:
        self.hidden_size = hidden_size
        self.max_position_embeddings = max_position_embeddings
        self.num_attention_heads = num_attention_heads
        self.num_hidden_layers = num_hidden_layers
        self.vocab_size = vocab_size
        self.epsilon = epsilon
        self.number_rep_kv = number_rep_kv
        self.num_key_value_heads = num_key_value_heads
        self.intermediate_size = intermediate_size
        self.head_dims = hidden_size // num_attention_heads
        self.kv_dims = hidden_size // num_key_value_heads

    fn __init__(inout self: Self) -> None:
        self.hidden_size = 512
        self.max_position_embeddings = 2048
        self.num_attention_heads = 8
        self.num_hidden_layers = 8
        self.vocab_size = 32000
        self.epsilon = 1e-5
        self.number_rep_kv = 1
        self.num_key_value_heads = 1
        self.intermediate_size = self.hidden_size * 4
        self.head_dims = self.hidden_size // self.num_attention_heads
        self.kv_dims = self.hidden_size // self.num_key_value_heads

    fn __init__(inout self: Self, inout buffer: FileBuffer) raises -> None:
        self.hidden_size = (
            buffer.data.offset(buffer.offset).bitcast[DType.int32]().load(0).to_int()
        )
        buffer.move_offset(4)
        self.intermediate_size = (
            buffer.data.offset(buffer.offset).bitcast[DType.int32]().load(0).to_int()
        )
        buffer.move_offset(4)
        self.num_hidden_layers = (
            buffer.data.offset(buffer.offset).bitcast[DType.int32]().load(0).to_int()
        )
        buffer.move_offset(4)
        self.num_attention_heads = (
            buffer.data.offset(buffer.offset).bitcast[DType.int32]().load(0).to_int()
        )
        buffer.move_offset(4)
        self.num_key_value_heads = (
            buffer.data.offset(buffer.offset).bitcast[DType.int32]().load(0).to_int()
        )
        buffer.move_offset(4)

        self.vocab_size = (
            buffer.data.offset(buffer.offset).bitcast[DType.int32]().load(0).to_int()
        )
        buffer.move_offset(4)
        self.max_position_embeddings = (
            buffer.data.offset(buffer.offset).bitcast[DType.int32]().load(0).to_int()
        )
        buffer.move_offset(4)
        self.head_dims = self.hidden_size // self.num_attention_heads
        self.kv_dims = (
            self.num_key_value_heads * self.hidden_size
        ) // self.num_attention_heads
        self.number_rep_kv = self.num_attention_heads // self.num_key_value_heads
        self.epsilon = 1e-5
        return None

    fn print_config(self: Self) -> None:
        print("\033[1;36mHidden Size             : ", self.hidden_size)
        print("Max Position Embeddings : ", self.max_position_embeddings)
        print("Num Attention Heads     : ", self.num_attention_heads)
        print("Num Hidden Layers       : ", self.num_hidden_layers)
        print("Vocab Size              : ", self.vocab_size)
        print("RMS Norm Epsilon        : ", self.epsilon)
        print("Number Repeat Key Value : ", self.number_rep_kv)
        print("Number Key Value Heads  : ", self.num_key_value_heads)
        print("Intermediate Size       : ", self.intermediate_size)
        print("HEAD DIMS               : ", self.head_dims)
        print("KV DIMS                 : ", self.kv_dims)
        print_no_newline("\033[1;0m")


struct LlamaRunState[T: DType]:
    var x: Tensor[T]
    var residual: Tensor[T]
    var residual2: Tensor[T]
    var w1: Tensor[T]
    var w3: Tensor[T]
    var q: Tensor[T]
    var k: TensorSlice[T]
    var v: TensorSlice[T]
    var att: Tensor[T]
    var logits: Tensor[T]
    var key_cache: Tensor[T]
    var value_cache: Tensor[T]

    fn __init__(inout self, config: LlamaConfig) raises:
        self.x = Tensor[T](config.hidden_size)
        self.residual = Tensor[T](config.hidden_size)
        self.residual2 = Tensor[T](config.hidden_size)
        self.w1 = Tensor[T](config.intermediate_size)
        self.w3 = Tensor[T](config.intermediate_size)
        self.q = Tensor[T](config.hidden_size)
        self.att = Tensor[T](config.num_attention_heads, config.max_position_embeddings)
        self.logits = Tensor[T](config.vocab_size)
        self.key_cache = Tensor[T](
            config.num_hidden_layers, config.max_position_embeddings, config.kv_dims
        )
        self.value_cache = Tensor[T](
            config.num_hidden_layers, config.max_position_embeddings, config.kv_dims
        )
        self.k = TensorSlice[T](Tensor[T](TensorShape(1, config.kv_dims)), 1)
        self.v = TensorSlice[T](Tensor[T](TensorShape(1, config.kv_dims)), 1)


fn load_weights[T: DType](inout buf: FileBuffer, *dims: Int) raises -> Tensor[T]:
    let shape = TensorShape(dims)
    let result_data = DTypePointer[T].alloc(shape.num_elements())
    memcpy(
        result_data,
        buf.read_numerical_value_dynamic[T](shape.num_elements()),
        shape.num_elements(),
    )
    return Tensor[T](result_data, shape)


struct LlamaWeights[T: DType]:
    var wte: Tensor[T]
    var fcr: Tensor[T]
    var fci: Tensor[T]
    var input_layernorm_weight: Tensor[T]
    var q_proj: Tensor[T]
    var k_proj: Tensor[T]
    var v_proj: Tensor[T]
    var o_proj: Tensor[T]
    var post_layernorm_weight: Tensor[T]
    var w1: Tensor[T]
    var w3: Tensor[T]
    var w2: Tensor[T]
    var norm: Tensor[T]
    var wcls: Tensor[T]

    fn __init__(
        inout self, config: LlamaConfig, shared_weights: Int, inout buf: FileBuffer
    ) raises:
        self.wte = load_weights[T](buf, config.vocab_size, config.hidden_size)
        self.input_layernorm_weight = load_weights[T](
            buf, config.num_hidden_layers, config.hidden_size
        )
        self.q_proj = load_weights[T](
            buf, config.num_hidden_layers, config.hidden_size, config.hidden_size
        )
        self.k_proj = load_weights[T](
            buf, config.num_hidden_layers, config.kv_dims, config.hidden_size
        )
        self.v_proj = load_weights[T](
            buf, config.num_hidden_layers, config.kv_dims, config.hidden_size
        )
        self.o_proj = load_weights[T](
            buf, config.num_hidden_layers, config.hidden_size, config.hidden_size
        )
        self.post_layernorm_weight = load_weights[T](
            buf, config.num_hidden_layers, config.hidden_size
        )
        self.w1 = load_weights[T](
            buf, config.num_hidden_layers, config.intermediate_size, config.hidden_size
        )
        self.w2 = load_weights[T](
            buf, config.num_hidden_layers, config.hidden_size, config.intermediate_size
        )
        self.w3 = load_weights[T](
            buf, config.num_hidden_layers, config.intermediate_size, config.hidden_size
        )
        self.norm = load_weights[T](buf, config.hidden_size)
        self.fcr = load_weights[T](
            buf, config.max_position_embeddings, config.head_dims // 2
        )
        self.fci = load_weights[T](
            buf, config.max_position_embeddings, config.head_dims // 2
        )
        if shared_weights:
            self.wcls = self.wte
        else:
            self.wcls = load_weights[T](buf, config.vocab_size, config.hidden_size)


fn rope_rotation_llama[
    T: DType, cores: Int
](
    inout q: Tensor[T],
    inout k: TensorSlice[T],
    freq_cis_real_row: TensorSlice[T],
    freq_cis_imag_row: TensorSlice[T],
    config: LlamaConfig,
) -> None:
    # stories model, llama2
    let head_dims = config.head_dims

    @parameter
    fn head_loop(i: Int):
        for j in range(0, config.head_dims, 2):
            let fcr = freq_cis_real_row[j // 2]
            let fci = freq_cis_imag_row[j // 2]
            let q0 = q[i * head_dims + j]
            let q1 = q[i * head_dims + j + 1]
            q[i * head_dims + j] = q0 * fcr - q1 * fci
            q[i * head_dims + j + 1] = q0 * fci + q1 * fcr
            if i < config.num_key_value_heads:
                let k0 = k[i * head_dims + j]
                let k1 = k[i * head_dims + j + 1]
                k[i * head_dims + j] = k0 * fcr - k1 * fci
                k[i * head_dims + j + 1] = k0 * fci + k1 * fcr

    parallelize[head_loop](config.num_attention_heads, cores)


@always_inline
fn llama_forward[
    T: DType, nelts: Int, cores: Int
](
    input_id: Int,
    position_id: Int,
    config: LlamaConfig,
    inout state: LlamaRunState[T],
    weights: LlamaWeights[T],
) -> None:
    let hidden_size = config.hidden_size
    let intermediate_size = config.intermediate_size
    let head_dims = config.head_dims
    let kv_dims = config.kv_dims
    let number_rep_kv = config.number_rep_kv

    let content_row = weights.wte.data().offset(input_id * hidden_size)
    memcpy[T](state.x.data(), content_row, hidden_size)

    let freq_cis_real_row = TensorSlice[T](weights.fcr, position_id)
    let freq_cis_imag_row = TensorSlice[T](weights.fci, position_id)

    for layer_inedx in range(config.num_hidden_layers):
        rmsnorm[T, nelts](
            state.residual,
            state.x,
            TensorSlice[T](weights.input_layernorm_weight, layer_inedx),
        )

        let cache_padding = layer_inedx * config.max_position_embeddings * config.kv_dims

        state.k = TensorSlice[T](state.key_cache, layer_inedx, position_id)
        state.v = TensorSlice[T](state.value_cache, layer_inedx, position_id)

        if kv_dims == hidden_size:
            batch_matmul_row[T, nelts, cores, 3](
                StaticTuple[3, DTypePointer[T]](
                    state.q.data(), state.k.data(), state.v.data()
                ),
                state.residual.data(),
                StaticTuple[3, DTypePointer[T]](
                    TensorSlice[T](weights.q_proj, layer_inedx).data(),
                    TensorSlice[T](weights.k_proj, layer_inedx).data(),
                    TensorSlice[T](weights.v_proj, layer_inedx).data(),
                ),
                hidden_size,
                hidden_size,
            )
        else:
            matmul_row[T, nelts, cores](
                state.q, state.residual, TensorSlice[T](weights.q_proj, layer_inedx)
            )
            batch_matmul_row[T, nelts, cores, 2](
                StaticTuple[2, DTypePointer[T]](state.k.data(), state.v.data()),
                state.residual.data(),
                StaticTuple[2, DTypePointer[T]](
                    TensorSlice[T](weights.k_proj, layer_inedx).data(),
                    TensorSlice[T](weights.v_proj, layer_inedx).data(),
                ),
                kv_dims,
                hidden_size,
            )

        rope_rotation_llama[T, cores](
            state.q, state.k, freq_cis_real_row, freq_cis_imag_row, config
        )

        memset_zero[T](state.residual.data(), state.residual.num_elements())

        @parameter
        fn loop_over_heads(h: Int):
            let q_offset = h * head_dims
            let att_offset = h * config.max_position_embeddings
            for t in range(position_id + 1):
                let k_offset = cache_padding + t * kv_dims + (
                    h // number_rep_kv
                ) * head_dims
                var score: SIMD[T, 1] = 0.0

                @parameter
                fn score_fn[_nelts: Int](i: Int):
                    score += (
                        state.q.simd_load[_nelts](q_offset + i)
                        * state.key_cache.simd_load[_nelts](k_offset + i)
                    ).reduce_add()

                vectorize[nelts, score_fn](head_dims)
                score /= math.sqrt[T, 1](head_dims)
                state.att[att_offset + t] = score
            scope_softmax[T, nelts](state.att, att_offset, att_offset + position_id + 1)

            let residual_offset = h * head_dims
            for t in range(position_id + 1):
                let v_offset = cache_padding + t * kv_dims + (
                    h // number_rep_kv
                ) * head_dims

                let a = state.att[att_offset + t]

                @parameter
                fn xb_accumulate[_nelts: Int](i: Int):
                    let xbi = state.residual.simd_load[_nelts](
                        residual_offset + i
                    ) + a * state.value_cache.simd_load[_nelts](v_offset + i)
                    state.residual.simd_store[_nelts](residual_offset + i, xbi)

                vectorize[nelts, xb_accumulate](head_dims)

        parallelize[loop_over_heads](config.num_attention_heads, cores)

        matmul_row[T, nelts, cores](
            state.residual2, state.residual, TensorSlice[T](weights.o_proj, layer_inedx)
        )

        tensor_add[T, nelts](state.x, state.residual2)

        rmsnorm[T, nelts](
            state.residual,
            state.x,
            TensorSlice[T](weights.post_layernorm_weight, layer_inedx),
        )

        batch_matmul_row[T, nelts, cores, 2](
            StaticTuple[2, DTypePointer[T]](state.w1.data(), state.w3.data()),
            state.residual.data(),
            StaticTuple[2, DTypePointer[T]](
                TensorSlice[T](weights.w1, layer_inedx).data(),
                TensorSlice[T](weights.w3, layer_inedx).data(),
            ),
            intermediate_size,
            hidden_size,
        )

        @parameter
        fn silu[_nelts: Int](i: Int):
            let initial_hb = state.w1.simd_load[_nelts](i)
            let hbi = initial_hb * (1.0 / (1.0 + math.exp(-initial_hb)))
            state.w1.simd_store[_nelts](i, hbi * state.w3.simd_load[_nelts](i))

        vectorize[nelts, silu](intermediate_size)
        matmul_row[T, nelts, cores](
            state.residual, state.w1, TensorSlice[T](weights.w2, layer_inedx)
        )

        tensor_add[T, nelts](state.x, state.residual)

    rmsnorm[T, nelts](state.x, state.x, weights.norm)

    matmul_row[T, nelts, cores](state.logits, state.x, weights.wcls)
